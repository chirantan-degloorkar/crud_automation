{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\work-projects\\crud_automation\\venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in d:\\work-projects\\crud_automation\\venv\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: pyodbc in d:\\work-projects\\crud_automation\\venv\\lib\\site-packages (5.2.0)\n",
      "Requirement already satisfied: python-dotenv in d:\\work-projects\\crud_automation\\venv\\lib\\site-packages (1.0.1)\n",
      "Collecting openai\n",
      "  Downloading openai-1.59.5-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\work-projects\\crud_automation\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\work-projects\\crud_automation\\venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\work-projects\\crud_automation\\venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.8.2-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.10.4-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>4 in d:\\work-projects\\crud_automation\\venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\work-projects\\crud_automation\\venv\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\work-projects\\crud_automation\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in d:\\work-projects\\crud_automation\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.27.2-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: six>=1.5 in d:\\work-projects\\crud_automation\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in d:\\work-projects\\crud_automation\\venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.59.5-py3-none-any.whl (454 kB)\n",
      "   ---------------------------------------- 0.0/454.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 454.8/454.8 kB 14.3 MB/s eta 0:00:00\n",
      "Downloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "   ---------------------------------------- 0.0/96.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 96.0/96.0 kB ? eta 0:00:00\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "   ---------------------------------------- 0.0/73.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 73.5/73.5 kB ? eta 0:00:00\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.6/78.6 kB 4.3 MB/s eta 0:00:00\n",
      "Downloading jiter-0.8.2-cp312-cp312-win_amd64.whl (204 kB)\n",
      "   ---------------------------------------- 0.0/204.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 204.7/204.7 kB 12.2 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.10.4-py3-none-any.whl (431 kB)\n",
      "   ---------------------------------------- 0.0/431.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 431.8/431.8 kB 26.3 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.27.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------  2.0/2.0 MB 63.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 42.1 MB/s eta 0:00:00\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: sniffio, pydantic-core, jiter, h11, distro, annotated-types, pydantic, httpcore, anyio, httpx, openai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.8.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 jiter-0.8.2 openai-1.59.5 pydantic-2.10.4 pydantic-core-2.27.2 sniffio-1.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas numpy pyodbc python-dotenv openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pyodbc\n",
    "\n",
    "def get_connection(driver, server, database):\n",
    "    \"\"\"Create a connection to the SQL Server database.\"\"\"\n",
    "    try:\n",
    "        connection_string = f\"\"\"\n",
    "            DRIVER={driver};\n",
    "            SERVER={server};\n",
    "            DATABASE={database};\n",
    "            Trusted_Connection=yes;\n",
    "            \"\"\"\n",
    "        connection = pyodbc.connect(connection_string)\n",
    "        return connection\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "driver = 'SQL Server'\n",
    "database = 'AdventureWorks2022'\n",
    "server = 'ATISL400'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = get_connection(driver, server, database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Purchasing', 'ProductVendor'),\n",
       " ('Purchasing', 'PurchaseOrderDetail'),\n",
       " ('Purchasing', 'PurchaseOrderHeader'),\n",
       " ('Purchasing', 'ShipMethod'),\n",
       " ('Purchasing', 'Vendor')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = f\"\"\"\n",
    "SELECT \n",
    "    TABLE_SCHEMA,\n",
    "    TABLE_NAME\n",
    "FROM \n",
    "    INFORMATION_SCHEMA.TABLES\n",
    "WHERE \n",
    "    TABLE_TYPE = 'BASE TABLE'\n",
    "    AND TABLE_SCHEMA = 'Purchasing'  -- replace 'dbo' with your schema name\n",
    "ORDER BY \n",
    "    TABLE_NAME;\n",
    "    \"\"\"\n",
    "    \n",
    "with conn.cursor() as cursor:\n",
    "    cursor.execute(q)\n",
    "    schema = cursor.fetchall()\n",
    "\n",
    "schema\n",
    "# df = pd.DataFrame(schema, columns=[column[0] for column in cursor.description])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import sqlite3\n",
    " \n",
    "# Connect to SQL Server and restore the .bak file\n",
    "# sql_server_conn_str = 'DRIVER={ODBC Driver 17 for SQL Server};SERVER=YourServerName;DATABASE=master;UID=YourUsername;PWD=YourPassword'\n",
    "# with pyodbc.connect(sql_server_conn_str) as sql_conn:\n",
    "#     sql_cursor = sql_conn.cursor()\n",
    "#     sql_cursor.execute(\"RESTORE DATABASE YourDatabaseName FROM DISK = 'C:\\\\YourBackupFile.bak' WITH REPLACE\")\n",
    "conn = get_connection(driver, server, database)\n",
    "\n",
    "with conn as sql_conn:\n",
    "    sql_cursor = sql_conn.cursor()\n",
    "    sql_cursor.execute(\"RESTORE DATABASE AdventureWorks2022 FROM DISK = 'C:\\\\Users\\\\Chirantan_Degloorkar\\\\Downloads\\\\AdventureWorks2022.bak' WITH REPLACE\")\n",
    "# Connect to the restored database and extract data\n",
    "with conn as sql_conn:\n",
    "    sql_cursor = sql_conn.cursor()\n",
    "    sql_cursor.execute(\"SELECT * FROM YourTableName\")\n",
    "    rows = sql_cursor.fetchall()\n",
    " \n",
    "# Create a new SQLite database\n",
    "sqlite_conn = sqlite3.connect('your_sqlite_db.db')\n",
    "sqlite_cursor = sqlite_conn.cursor()\n",
    "sqlite_cursor.execute(\"CREATE TABLE YourTableName (col1, col2, ...)\")\n",
    " \n",
    "# Insert data into the SQLite database\n",
    "sqlite_cursor.executemany(\"INSERT INTO YourTableName VALUES (?, ?, ...)\", rows)\n",
    "sqlite_conn.commit()\n",
    "sqlite_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.7 kB ? eta -:--:--\n",
      "     ------- -------------------------------- 10.2/57.7 kB ? eta -:--:--\n",
      "     ------------- ------------------------ 20.5/57.7 kB 217.9 kB/s eta 0:00:01\n",
      "     -------------------------- ----------- 41.0/57.7 kB 326.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 57.7/57.7 kB 302.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in d:\\work-projects\\crud_automation\\venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "   -------------------- ------------------- 41.0/78.5 kB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 71.7/78.5 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 78.5/78.5 kB 875.6 kB/s eta 0:00:00\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chirantan_Degloorkar\\AppData\\Local\\Temp\\ipykernel_20844\\2069422936.py:16: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 71 tables to migrate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/71 [00:00<?, ?it/s]C:\\Users\\Chirantan_Degloorkar\\AppData\\Local\\Temp\\ipykernel_20844\\2069422936.py:51: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, sql_server_conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Migrating table: Sales.SalesTaxRate\n",
      "Successfully migrated 29 rows from Sales.SalesTaxRate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/71 [00:00<00:07,  9.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Migrating table: Sales.PersonCreditCard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/71 [00:00<00:13,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated 19118 rows from Sales.PersonCreditCard\n",
      "\n",
      "Migrating table: Person.PersonPhone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 6/71 [00:00<00:06,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated 19972 rows from Person.PersonPhone\n",
      "\n",
      "Migrating table: Sales.SalesTerritory\n",
      "Successfully migrated 10 rows from Sales.SalesTerritory\n",
      "\n",
      "Migrating table: Person.PhoneNumberType\n",
      "Successfully migrated 3 rows from Person.PhoneNumberType\n",
      "\n",
      "Migrating table: Production.Product\n",
      "Successfully migrated 504 rows from Production.Product\n",
      "\n",
      "Migrating table: Sales.SalesTerritoryHistory\n",
      "Successfully migrated 17 rows from Sales.SalesTerritoryHistory\n",
      "\n",
      "Migrating table: Production.ScrapReason\n",
      "Successfully migrated 16 rows from Production.ScrapReason\n",
      "\n",
      "Migrating table: HumanResources.Shift\n",
      "Successfully migrated 3 rows from HumanResources.Shift\n",
      "\n",
      "Migrating table: Production.ProductCategory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 13/71 [00:00<00:02, 19.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated 4 rows from Production.ProductCategory\n",
      "\n",
      "Migrating table: Purchasing.ShipMethod\n",
      "Successfully migrated 5 rows from Purchasing.ShipMethod\n",
      "\n",
      "Migrating table: Production.ProductCostHistory\n",
      "Successfully migrated 395 rows from Production.ProductCostHistory\n",
      "\n",
      "Migrating table: Production.ProductDescription\n",
      "Successfully migrated 762 rows from Production.ProductDescription\n",
      "\n",
      "Migrating table: Sales.ShoppingCartItem\n",
      "Successfully migrated 3 rows from Sales.ShoppingCartItem\n",
      "\n",
      "Migrating table: Production.ProductDocument\n",
      "Successfully migrated 32 rows from Production.ProductDocument\n",
      "\n",
      "Migrating table: dbo.DatabaseLog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 16/71 [00:01<00:03, 14.97it/s]C:\\Users\\Chirantan_Degloorkar\\AppData\\Local\\Temp\\ipykernel_20844\\2069422936.py:51: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, sql_server_conn)\n",
      " 28%|██▊       | 20/71 [00:01<00:02, 19.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated 1596 rows from dbo.DatabaseLog\n",
      "\n",
      "Migrating table: Production.ProductInventory\n",
      "Successfully migrated 1069 rows from Production.ProductInventory\n",
      "\n",
      "Migrating table: Sales.SpecialOffer\n",
      "Successfully migrated 16 rows from Sales.SpecialOffer\n",
      "\n",
      "Migrating table: dbo.ErrorLog\n",
      "Successfully migrated 0 rows from dbo.ErrorLog\n",
      "\n",
      "Migrating table: Production.ProductListPriceHistory\n",
      "Successfully migrated 395 rows from Production.ProductListPriceHistory\n",
      "\n",
      "Migrating table: Person.Address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 26/71 [00:02<00:03, 12.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated 19614 rows from Person.Address\n",
      "\n",
      "Migrating table: Sales.SpecialOfferProduct\n",
      "Successfully migrated 538 rows from Sales.SpecialOfferProduct\n",
      "\n",
      "Migrating table: Production.ProductModel\n",
      "Successfully migrated 128 rows from Production.ProductModel\n",
      "\n",
      "Migrating table: Person.AddressType\n",
      "Successfully migrated 6 rows from Person.AddressType\n",
      "\n",
      "Migrating table: Person.StateProvince\n",
      "Successfully migrated 181 rows from Person.StateProvince\n",
      "\n",
      "Migrating table: Production.ProductModelIllustration\n",
      "Successfully migrated 7 rows from Production.ProductModelIllustration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 29/71 [00:02<00:03, 12.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Migrating table: dbo.AWBuildVersion\n",
      "Successfully migrated 1 rows from dbo.AWBuildVersion\n",
      "\n",
      "Migrating table: Production.ProductModelProductDescriptionCulture\n",
      "Successfully migrated 762 rows from Production.ProductModelProductDescriptionCulture\n",
      "\n",
      "Migrating table: Production.BillOfMaterials\n",
      "Successfully migrated 2679 rows from Production.BillOfMaterials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 31/71 [00:02<00:03, 12.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Migrating table: Sales.Store\n",
      "Successfully migrated 701 rows from Sales.Store\n",
      "\n",
      "Migrating table: Production.ProductPhoto\n",
      "Successfully migrated 101 rows from Production.ProductPhoto\n",
      "\n",
      "Migrating table: Production.ProductProductPhoto\n",
      "Successfully migrated 504 rows from Production.ProductProductPhoto\n",
      "\n",
      "Migrating table: Production.TransactionHistory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 33/71 [00:05<00:15,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated 113443 rows from Production.TransactionHistory\n",
      "\n",
      "Migrating table: Production.ProductReview\n",
      "Successfully migrated 4 rows from Production.ProductReview\n",
      "\n",
      "Migrating table: Person.BusinessEntity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 35/71 [00:05<00:12,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated 20777 rows from Person.BusinessEntity\n",
      "\n",
      "Migrating table: Production.TransactionHistoryArchive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 37/71 [00:08<00:20,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated 89253 rows from Production.TransactionHistoryArchive\n",
      "\n",
      "Migrating table: Production.ProductSubcategory\n",
      "Successfully migrated 37 rows from Production.ProductSubcategory\n",
      "\n",
      "Migrating table: Person.BusinessEntityAddress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 41/71 [00:08<00:10,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated 19614 rows from Person.BusinessEntityAddress\n",
      "\n",
      "Migrating table: Purchasing.ProductVendor\n",
      "Successfully migrated 460 rows from Purchasing.ProductVendor\n",
      "\n",
      "Migrating table: Person.BusinessEntityContact\n",
      "Successfully migrated 909 rows from Person.BusinessEntityContact\n",
      "\n",
      "Migrating table: Production.UnitMeasure\n",
      "Successfully migrated 38 rows from Production.UnitMeasure\n",
      "\n",
      "Migrating table: Purchasing.Vendor\n",
      "Successfully migrated 104 rows from Purchasing.Vendor\n",
      "\n",
      "Migrating table: Person.ContactType\n",
      "Successfully migrated 20 rows from Person.ContactType\n",
      "\n",
      "Migrating table: Sales.CountryRegionCurrency\n",
      "Successfully migrated 109 rows from Sales.CountryRegionCurrency\n",
      "\n",
      "Migrating table: Person.CountryRegion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 45/71 [00:08<00:05,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated 238 rows from Person.CountryRegion\n",
      "\n",
      "Migrating table: Production.WorkOrder\n",
      "Successfully migrated 72591 rows from Production.WorkOrder\n",
      "\n",
      "Migrating table: Purchasing.PurchaseOrderDetail\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 47/71 [00:11<00:11,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated 8845 rows from Purchasing.PurchaseOrderDetail\n",
      "\n",
      "Migrating table: Sales.CreditCard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 49/71 [00:12<00:09,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated 19118 rows from Sales.CreditCard\n",
      "\n",
      "Migrating table: Production.Culture\n",
      "Successfully migrated 8 rows from Production.Culture\n",
      "\n",
      "Migrating table: Production.WorkOrderRouting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 51/71 [00:16<00:17,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated 67131 rows from Production.WorkOrderRouting\n",
      "\n",
      "Migrating table: Sales.Currency\n",
      "Successfully migrated 105 rows from Sales.Currency\n",
      "\n",
      "Migrating table: Purchasing.PurchaseOrderHeader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 52/71 [00:16<00:14,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated 4012 rows from Purchasing.PurchaseOrderHeader\n",
      "\n",
      "Migrating table: Sales.CurrencyRate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 53/71 [00:17<00:12,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated 13532 rows from Sales.CurrencyRate\n",
      "\n",
      "Migrating table: Sales.Customer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 54/71 [00:17<00:11,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated 19820 rows from Sales.Customer\n",
      "\n",
      "Migrating table: HumanResources.Department\n",
      "Successfully migrated 16 rows from HumanResources.Department\n",
      "\n",
      "Migrating table: Production.Document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 56/71 [00:18<00:09,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated 13 rows from Production.Document\n",
      "\n",
      "Migrating table: Sales.SalesOrderDetail\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 57/71 [00:24<00:25,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated 121317 rows from Sales.SalesOrderDetail\n",
      "\n",
      "Migrating table: Person.EmailAddress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 58/71 [00:25<00:19,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated 19972 rows from Person.EmailAddress\n",
      "\n",
      "Migrating table: HumanResources.Employee\n",
      "Successfully migrated 290 rows from HumanResources.Employee\n",
      "\n",
      "Migrating table: Sales.SalesOrderHeader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 60/71 [00:28<00:16,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated 31465 rows from Sales.SalesOrderHeader\n",
      "\n",
      "Migrating table: HumanResources.EmployeeDepartmentHistory\n",
      "Successfully migrated 296 rows from HumanResources.EmployeeDepartmentHistory\n",
      "\n",
      "Migrating table: HumanResources.EmployeePayHistory\n",
      "Successfully migrated 316 rows from HumanResources.EmployeePayHistory\n",
      "\n",
      "Migrating table: Sales.SalesOrderHeaderSalesReason\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 67/71 [00:28<00:01,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated 27647 rows from Sales.SalesOrderHeaderSalesReason\n",
      "\n",
      "Migrating table: Sales.SalesPerson\n",
      "Successfully migrated 17 rows from Sales.SalesPerson\n",
      "\n",
      "Migrating table: Production.Illustration\n",
      "Successfully migrated 5 rows from Production.Illustration\n",
      "\n",
      "Migrating table: HumanResources.JobCandidate\n",
      "Successfully migrated 13 rows from HumanResources.JobCandidate\n",
      "\n",
      "Migrating table: Production.Location\n",
      "Successfully migrated 14 rows from Production.Location\n",
      "\n",
      "Migrating table: Person.Password\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 69/71 [00:29<00:00,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated 19972 rows from Person.Password\n",
      "\n",
      "Migrating table: Sales.SalesPersonQuotaHistory\n",
      "Successfully migrated 163 rows from Sales.SalesPersonQuotaHistory\n",
      "\n",
      "Migrating table: Person.Person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:30<00:00,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated 19972 rows from Person.Person\n",
      "\n",
      "Migrating table: Sales.SalesReason\n",
      "Successfully migrated 10 rows from Sales.SalesReason\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_all_tables(conn):\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        TABLE_SCHEMA,\n",
    "        TABLE_NAME \n",
    "    FROM \n",
    "        INFORMATION_SCHEMA.TABLES \n",
    "    WHERE \n",
    "        TABLE_TYPE = 'BASE TABLE'\n",
    "    \"\"\"\n",
    "    return pd.read_sql(query, conn)\n",
    "\n",
    "def create_sqlite_table(df, table_name, sqlite_conn):\n",
    "    # Create table in SQLite using pandas\n",
    "    df.to_sql(table_name, sqlite_conn, if_exists='replace', index=False)\n",
    "\n",
    "def migrate_database():\n",
    "    # SQL Server connection\n",
    "    sql_server_conn = pyodbc.connect(\n",
    "        'DRIVER={SQL Server};'\n",
    "        'SERVER=ATISL400;'  # Replace with your server name\n",
    "        'DATABASE=AdventureWorks2022;'\n",
    "        'Trusted_Connection=yes;'\n",
    "    )\n",
    "\n",
    "    # SQLite connection\n",
    "    sqlite_conn = sqlite3.connect('adventureworks.db')\n",
    "\n",
    "    try:\n",
    "        # Get all tables\n",
    "        tables_df = get_all_tables(sql_server_conn)\n",
    "        \n",
    "        print(f\"Found {len(tables_df)} tables to migrate\")\n",
    "        \n",
    "        # Iterate through each table\n",
    "        for _, row in tqdm(tables_df.iterrows(), total=len(tables_df)):\n",
    "            schema = row['TABLE_SCHEMA']\n",
    "            table = row['TABLE_NAME']\n",
    "            full_table_name = f\"{schema}.{table}\"\n",
    "            \n",
    "            try:\n",
    "                print(f\"\\nMigrating table: {full_table_name}\")\n",
    "                \n",
    "                # Read data from SQL Server\n",
    "                query = f\"SELECT * FROM {full_table_name}\"\n",
    "                df = pd.read_sql(query, sql_server_conn)\n",
    "                \n",
    "                # Create table in SQLite\n",
    "                sqlite_table_name = f\"{schema}_{table}\"\n",
    "                create_sqlite_table(df, sqlite_table_name, sqlite_conn)\n",
    "                \n",
    "                print(f\"Successfully migrated {len(df)} rows from {full_table_name}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error migrating table {full_table_name}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Migration failed: {str(e)}\")\n",
    "        \n",
    "    finally:\n",
    "        sql_server_conn.close()\n",
    "        sqlite_conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    migrate_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
